{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from comtypes import CLSCTX_ALL\n",
    "from ctypes import POINTER, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configs\n",
    "# camera\n",
    "cam_width, cam_height = 1280, 880\n",
    "# display\n",
    "PINK = (255, 0, 255)\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "point_radius = 8\n",
    "line_thickness = 8\n",
    "# finger range\n",
    "thumb_idx_dist_range = (50, 250)\n",
    "lock_dist_lim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create volume interface\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "audio_interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(audio_interface, POINTER(IAudioEndpointVolume))\n",
    "min_vol, max_vol, _ = volume.GetVolumeRange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hand landmarks detector\n",
    "hand_detector = mp.solutions.hands.Hands(\n",
    "                    model_complexity=1, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5,\n",
    "                    static_image_mode=False,\n",
    "                    max_num_hands=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_dist(landmark1, landmark2):\n",
    "    x1, y1 = landmark1\n",
    "    x2, y2 = landmark2\n",
    "    return np.sqrt(np.square(x2-x1) + np.square(y2-y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_dist(landmark1, landmark2):\n",
    "    x1, y1, z1 = landmark1\n",
    "    x2, y2, z2 = landmark2\n",
    "    return np.sqrt(np.square(x2-x1) + np.square(y2-y1) + np.square(z2-z1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_list = []\n",
    "volume_locked = True\n",
    "prev_dist = 0\n",
    "# setup input stream, in this case, webcam\n",
    "stream = cv2.VideoCapture(0)\n",
    "stream.set(3, cam_width)\n",
    "stream.set(4, cam_height)\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    prev_img_load_time = time.time()\n",
    "    ret, img = stream.read()\n",
    "    # Ignore fail read image\n",
    "    if ret is False:\n",
    "        continue\n",
    "    # Process\n",
    "    # optional, you can just flip your camera\n",
    "    # img = cv2.flip(img, 0) \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hand_detector.process(img)\n",
    "    # Draw landmarks\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    landmarks_list.clear()\n",
    "    if results.multi_hand_landmarks:\n",
    "        for id, landmarks in enumerate(results.multi_hand_landmarks[0].landmark):\n",
    "            if id in [4, 8, 10, 12]: # ID of thumb, index, middle fingertip\n",
    "                x = int(landmarks.x*cam_width)\n",
    "                y = int(landmarks.y*cam_height + 30)\n",
    "                landmarks_list.append([x, y])\n",
    "        '''\n",
    "            Due to the order, landmarks_list should have len of 4, in which\n",
    "                                landmarks_list[0] is thumb's tip\n",
    "                                landmarks_list[1] is index finger's tip\n",
    "                                landmarks_list[2] is ring finger's tip\n",
    "                                landmarks_list[3] is ring finger's first neck\n",
    "        '''\n",
    "        thumb_idx_dist = get_2d_dist(landmarks_list[0], landmarks_list[1])\n",
    "        lock_dist = get_2d_dist(landmarks_list[2], landmarks_list[3])\n",
    "        # switch the lock's state if middle finger touched index finger and the touch speed reach a threshold\n",
    "        if lock_dist < lock_dist_lim and np.abs(lock_dist - prev_dist) > 30:\n",
    "            volume_locked = not volume_locked\n",
    "        # Only allow adjust volume if lock is off\n",
    "        if not volume_locked:\n",
    "            volume_level = np.interp(thumb_idx_dist, thumb_idx_dist_range, (min_vol, max_vol))\n",
    "            volume.SetMasterVolumeLevel(volume_level, None)\n",
    "            cv2.putText(img, f'Volume: {volume_level}', (30, 150), font, 0.5, PINK)\n",
    "        prev_dist = lock_dist\n",
    "        cv2.putText(img, f'Volume lock: {volume_locked}', (30, 120), font, 0.5, color=RED if volume_locked else GREEN)\n",
    "        cv2.putText(img, f'Thumb Index Dist: {round(thumb_idx_dist, 2)}', (30, 60), font, 0.5, PINK)\n",
    "        cv2.putText(img, f'Mid lock Dist: {round(lock_dist, 2)}', (30, 90), font, 0.5, PINK)\n",
    "        for landmark in landmarks_list:\n",
    "            cv2.circle(img, landmark, point_radius, RED, cv2.FILLED)\n",
    "        # cv2.circle(img, landmarks_list[0], point_radius, RED, cv2.FILLED)\n",
    "        # cv2.circle(img, landmarks_list[1], point_radius, RED, cv2.FILLED)\n",
    "        cv2.line(img, landmarks_list[0], landmarks_list[1], GREEN, line_thickness)\n",
    "    # Draw FPS\n",
    "    fps = int(1/(time.time() - prev_img_load_time))\n",
    "    cv2.putText(img, f'FPS : {fps}', (30, 30), font, 0.5, PINK)\n",
    "    # Show the frame\n",
    "    cv2.imshow('Hand Detector', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeAdjuster:\n",
    "    def __init__(self):\n",
    "        self.volume = None\n",
    "        self.stream = None\n",
    "        self.hand_detector = mp.solutions.hands.Hands(\n",
    "                                model_complexity=1, \n",
    "                                min_detection_confidence=0.5, \n",
    "                                min_tracking_confidence=0.5,\n",
    "                                static_image_mode=False,\n",
    "                                max_num_hands=1)\n",
    "        # display\n",
    "        self.colors = {\n",
    "            'pink' : (255, 0, 255),\n",
    "            'red' : (0, 0, 255),\n",
    "            'green' : (0, 255, 0)\n",
    "        }\n",
    "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        self.point_radius = 8\n",
    "        self.line_thickness = 8\n",
    "        # finger range\n",
    "        self.thumb_idx_dist_range = (50, 300)\n",
    "        self.lock_dist_lim = 1\n",
    "        # attr for hand detector\n",
    "        self.landmarks_list = []\n",
    "        self.volume_locked = True\n",
    "        self.prev_dist = 0\n",
    "\n",
    "    def setup(self):\n",
    "        # audio setup\n",
    "        devices = AudioUtilities.GetSpeakers()\n",
    "        audio_interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "        self.volume = cast(audio_interface, POINTER(IAudioEndpointVolume))\n",
    "        min_vol, max_vol, _ = self.volume.GetVolumeRange()\n",
    "        self.vol_range = (min_vol, max_vol)\n",
    "        # camera setup\n",
    "        self.stream = cv2.VideoCapture(0)\n",
    "        self.cam_size = (1280, 880)\n",
    "        self.stream.set(3, self.cam_size[0])\n",
    "        self.stream.set(4, self.cam_size[0])\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            prev_img_load_time = time.time()\n",
    "            ret, img = self.stream.read()\n",
    "            # Ignore fail read frame\n",
    "            if ret is False:\n",
    "                continue\n",
    "            # Process\n",
    "            # optional, you can just flip your camera\n",
    "            # img = cv2.flip(img, 0) \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hand_detector.process(img)\n",
    "            # Draw landmarks\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            self.landmarks_list.clear()\n",
    "            if results.multi_hand_landmarks:\n",
    "                for id, landmarks in enumerate(results.multi_hand_landmarks[0].landmark):\n",
    "                    if id in [4, 8, 10, 12]: # ID of thumb, index, middle fingertip\n",
    "                        x = int(landmarks.x*cam_width)\n",
    "                        y = int(landmarks.y*cam_height + 30)\n",
    "                        self.landmarks_list.append([x, y])\n",
    "                '''\n",
    "                    Due to the order, landmarks_list should have len of 4, in which\n",
    "                                        landmarks_list[0] is thumb's tip\n",
    "                                        landmarks_list[1] is index finger's tip\n",
    "                                        landmarks_list[2] is ring finger's tip\n",
    "                                        landmarks_list[3] is ring finger's first neck\n",
    "                '''\n",
    "                thumb_idx_dist = get_2d_dist(landmarks_list[0], landmarks_list[1])\n",
    "                lock_dist = get_2d_dist(landmarks_list[2], landmarks_list[3])\n",
    "                # switch the lock's state if middle finger touched index finger and the touch speed reach a threshold\n",
    "                if lock_dist < self.lock_dist_lim and np.abs(lock_dist - prev_dist) > 30:\n",
    "                    self.volume_locked = not self.volume_locked\n",
    "                # Only allow adjust volume if lock is off\n",
    "                if not self.volume_locked:\n",
    "                    volume_level = np.interp(thumb_idx_dist, thumb_idx_dist_range, self.vol_range)\n",
    "                    self.volume.SetMasterVolumeLevel(volume_level, None)\n",
    "                    cv2.putText(img, f'Volume: {volume_level}', (30, 60), font, 0.5, self.colors['pink'])\n",
    "                prev_dist = lock_dist\n",
    "                cv2.putText(img, f'Volume lock: {volume_locked}', (30, 90), font, 0.5, color=self.colors['red'] if volume_locked else self.colors['green'])\n",
    "                # cv2.putText(img, f'Thumb Index Dist: {round(thumb_idx_dist, 2)}', (30, 60), font, 0.5, PINK)\n",
    "                # cv2.putText(img, f'Mid Index Dist: {round(lock_dist, 2)}', (30, 90), font, 0.5, PINK)\n",
    "                cv2.circle(img, landmarks_list[0], point_radius, RED, cv2.FILLED)\n",
    "                cv2.circle(img, landmarks_list[1], point_radius, RED, cv2.FILLED)\n",
    "                cv2.line(img, landmarks_list[0], landmarks_list[1], GREEN, line_thickness)\n",
    "            # Draw FPS\n",
    "            fps = int(1/(time.time() - prev_img_load_time))\n",
    "            cv2.putText(img, f'FPS : {fps}', (30, 30), font, 0.5, PINK)\n",
    "            # Show the frame\n",
    "            cv2.imshow('frame', img)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "    def stop(self):\n",
    "        self.stream.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7e58b3a9bb02cd090814cef287ec8aadd79361ec07b9179adbce85ffc378b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
